{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n!pip install transformers\nimport keras\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nimport re\nimport string","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T17:23:21.436419Z","iopub.execute_input":"2021-07-05T17:23:21.436843Z","iopub.status.idle":"2021-07-05T17:23:43.941132Z","shell.execute_reply.started":"2021-07-05T17:23:21.436807Z","shell.execute_reply":"2021-07-05T17:23:43.940082Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.5.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.3.17)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.59.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (20.9)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.12.5)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('../input/datacsv/data.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:23:43.942748Z","iopub.execute_input":"2021-07-05T17:23:43.943054Z","iopub.status.idle":"2021-07-05T17:23:47.544494Z","shell.execute_reply.started":"2021-07-05T17:23:43.943024Z","shell.execute_reply":"2021-07-05T17:23:47.543578Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0  The Vatican Apostolic Library (), more commonl...   \n1  The Vatican Apostolic Library (), more commonl...   \n2  The Vatican Apostolic Library (), more commonl...   \n3  The Vatican Apostolic Library (), more commonl...   \n4  The Vatican Apostolic Library (), more commonl...   \n\n                           question                               answer  \\\n0  When was the Vat formally opened  It was formally established in 1475   \n1           what is the library for                             research   \n2                 for what subjects                     history, and law   \n3                               and     philosophy, science and theology   \n4          what was started in 2014                           a  project   \n\n                                         all_answers  start_id  end_id  \n0                       Formally established in 1475       151     179  \n1           he Vatican Library is a research library       454     494  \n2  Vatican Library is a research library for hist...       457     511  \n3  Vatican Library is a research library for hist...       457     545  \n4  March 2014, the Vatican Library began an initi...       769     879  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>all_answers</th>\n      <th>start_id</th>\n      <th>end_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>When was the Vat formally opened</td>\n      <td>It was formally established in 1475</td>\n      <td>Formally established in 1475</td>\n      <td>151</td>\n      <td>179</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>what is the library for</td>\n      <td>research</td>\n      <td>he Vatican Library is a research library</td>\n      <td>454</td>\n      <td>494</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>for what subjects</td>\n      <td>history, and law</td>\n      <td>Vatican Library is a research library for hist...</td>\n      <td>457</td>\n      <td>511</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>and</td>\n      <td>philosophy, science and theology</td>\n      <td>Vatican Library is a research library for hist...</td>\n      <td>457</td>\n      <td>545</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Vatican Apostolic Library (), more commonl...</td>\n      <td>what was started in 2014</td>\n      <td>a  project</td>\n      <td>March 2014, the Vatican Library began an initi...</td>\n      <td>769</td>\n      <td>879</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class Sample:\n  def __init__(self, context, question, start_char_idx= None, answer_text = None, all_answers = None):\n    self.skip = False\n    self.context = context\n    self.question = question\n    self.answer_text = answer_text\n    self.start_char_idx = start_char_idx\n    self.start_token_idx = -1\n    self.end_token_idx = -1\n    self.all_answers = all_answers\n\n  def pre_process(self):\n    \n    context = \" \".join(str(self.context).split())\n    \n    question = \" \".join(str(self.question).split())\n    tokenized_context = tokenizer.encode(context)\n    tokenized_question = tokenizer.encode(question)\n\n    if self.answer_text is not None:\n        answer = \" \".join(str(self.answer_text).split())\n\n        end_char_id = self.start_char_idx + len(self.answer_text)\n        if end_char_id >= len(context):\n            self.skip = True\n            return\n      \n        is_ans_in_context = [0]*len(context)\n\n        for i in range(self.start_char_idx, end_char_id):\n            is_ans_in_context[i] = 1\n      \n        ans_token_id = []\n\n        for idx, (start, end) in enumerate(tokenized_context.offsets):\n            if sum(is_ans_in_context[start:end])>0:\n                  ans_token_id.append(idx)\n      \n        if len(ans_token_id)==0:\n            self.skip = True\n            return\n      \n        self.start_token_idx = ans_token_id[0]\n        self.end_token_idx = ans_token_id[-1]\n\n    input_ids = tokenized_context.ids + tokenized_question.ids[:]\n    token_type_ids = [0]*len(tokenized_context.ids) + [1]*len(tokenized_question.ids)\n    attention_mask = [0]*len(input_ids)\n\n    padding_len = max_len - len(input_ids)\n\n    if padding_len >0:\n        input_ids = input_ids + ([0]*padding_len)\n        attention_mask = attention_mask + ([0]*padding_len)\n        token_type_ids = token_type_ids + ([0]*padding_len)\n    \n    elif padding_len<0:\n        self.skip = True\n        return\n    \n    self.context_token_to_char = tokenized_context.offsets\n    self.input_word_ids = input_ids\n    self.input_type_ids = token_type_ids\n    self.input_mask = attention_mask\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:54:18.780615Z","iopub.execute_input":"2021-07-05T17:54:18.781250Z","iopub.status.idle":"2021-07-05T17:54:18.796217Z","shell.execute_reply.started":"2021-07-05T17:54:18.781184Z","shell.execute_reply":"2021-07-05T17:54:18.795265Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"max_len = 400\n\ndef get_examples(data):\n  examples = []\n#   print(len(data['question']))\n  for i in range(len(data['question'])):\n    if data['answer'][i] is not None:\n      ex = Sample(data['text'][i], data['question'][i], data['start_id'][i], data['answer'][i],[data['answer'][i], data['all_answers'][i]] )\n    else:\n      ex = Sample(data['text'][i], data['question'][i])\n    ex.pre_process()\n    examples.append(ex)\n#     if i==50:\n#         break\n    \n  return examples\n  \ndef create_dataset(examples):\n  dataset_dict = {\n        \"input_word_ids\": [],\n        \"input_type_ids\": [],\n        \"input_mask\": [],\n        \"start_token_idx\": [],\n        \"end_token_idx\": [],\n    }\n  for ex in examples:\n    if ex.skip==False:\n      # print(ex.input_type_ids)\n      for key in dataset_dict:\n        dataset_dict[key].append(getattr(ex, key))\n  for key in dataset_dict:\n    dataset_dict[key] = np.array(dataset_dict[key])\n    print(key, dataset_dict[key].shape)\n\n#   data_pd = pd.DataFrame.from_dict(dataset_dict)\n#   data_pd.to_pickle(\"/content/drive/MyDrive/NLP/final_dataset.pkl\")\n\n  train_x = np.array([dataset_dict[\"input_word_ids\"],\n         dataset_dict[\"input_mask\"],\n         dataset_dict[\"input_type_ids\"]])\n  train_y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n\n  return train_x, train_y\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:23:47.564031Z","iopub.execute_input":"2021-07-05T17:23:47.564462Z","iopub.status.idle":"2021-07-05T17:23:47.578971Z","shell.execute_reply.started":"2021-07-05T17:23:47.564419Z","shell.execute_reply":"2021-07-05T17:23:47.578154Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def generator(data, batch_size):\n    num_of_samples = len(x_train[0])\n    num_of_batches = num_of_samples//batch_size\n    \n    counter = 0\n    while 1:\n        examples = get_examples(data.iloc[batch_size*counter:batch_size*(counter+1), :])\n        X_batch, Y_batch_start, Y_batch_end = create_dataset(examples)\n#         Y_batch_end = y_train_end[:][batch_size*counter : batch_size*(counter+1)][:]\n        counter +=1\n        yield [X_batch[0], X_batch[1], X_batch[2]], (Y_batch_start, Y_batch_end)\n        \n        if counter>=num_of_batches:\n            counter=0\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T10:28:00.769566Z","iopub.execute_input":"2021-07-05T10:28:00.7699Z","iopub.status.idle":"2021-07-05T10:28:00.776056Z","shell.execute_reply.started":"2021-07-05T10:28:00.76987Z","shell.execute_reply":"2021-07-05T10:28:00.774847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ValidationCallback(keras.callbacks.Callback): \n    def normalize_text(self, text): \n        text = text.lower() \n        text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n\n        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n        text = re.sub(regex, \" \", text)\n        text = \" \".join(text.split())\n        return text\n    \n    def __init__(self, x_eval, y_eval): \n        self.x_eval = x_eval \n        self.y_eval = y_eval\n\n    def on_epoch_end(self, epoch, logs = None): \n        pred_start, pred_end = self.model.predict(self.x_eval) \n        count = 0 \n        eval_examples_no_skip = [_ for _ in examples if _.skip==False]\n\n        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n          squad_eg = eval_examples_no_skip[idx]\n\n          offsets = squad_eg.context_token_to_char\n          start = np.argmax(start)\n          end = np.argmin(end)\n\n          if start >= len(offsets):\n            continue\n\n          pred_char_start = offsets[start][0]\n          if end<len(offsets):\n            pred_char_end = offsets[end][1]\n            pred_char_ans = squad_eg.context[pred_char_start:pred_char_end]\n\n          else:\n            pred_char_ans = squad_eg.context[pred_char_start:]\n\n          normalized_pred_ans = self.normalize_text(pred_char_ans)\n          normalized_true_ans = [self.normalize_text(_) for _ in squad_eg.all_answers]\n\n          if normalized_pred_ans in normalized_true_ans:\n            count +=1\n\n        acc = count/len(self.y_eval[0])\n        print(f\"\\nepoch={epoch + 1}, exact match score={acc:.2f}\") ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:23:47.580446Z","iopub.execute_input":"2021-07-05T17:23:47.580816Z","iopub.status.idle":"2021-07-05T17:23:47.597515Z","shell.execute_reply.started":"2021-07-05T17:23:47.580785Z","shell.execute_reply":"2021-07-05T17:23:47.596412Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split\nfrom tokenizers import BertWordPieceTokenizer\n\ninput_word_ids = tf.keras.layers.Input(shape = (max_len, ), dtype = tf.int32, name = 'input_word_ids')\ninput_mask = tf.keras.layers.Input(shape = (max_len, ), dtype = tf.int32, name = 'input_mask')\ninput_type_ids = tf.keras.layers.Input(shape = (max_len, ), dtype = tf.int32, name = 'input_type_ids')\n\nbert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable = True)\npooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = BertWordPieceTokenizer(vocab = vocab_file, lowercase = True )\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:23:47.599223Z","iopub.execute_input":"2021-07-05T17:23:47.599647Z","iopub.status.idle":"2021-07-05T17:24:10.185744Z","shell.execute_reply.started":"2021-07-05T17:23:47.599601Z","shell.execute_reply":"2021-07-05T17:24:10.184634Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"examples = get_examples(data)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:10:34.385439Z","iopub.execute_input":"2021-07-05T11:10:34.385803Z","iopub.status.idle":"2021-07-05T11:13:50.235559Z","shell.execute_reply.started":"2021-07-05T11:10:34.385773Z","shell.execute_reply":"2021-07-05T11:13:50.234572Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"len(examples)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T10:56:29.183943Z","iopub.execute_input":"2021-07-05T10:56:29.184288Z","iopub.status.idle":"2021-07-05T10:56:29.191472Z","shell.execute_reply.started":"2021-07-05T10:56:29.184248Z","shell.execute_reply":"2021-07-05T10:56:29.190398Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"108647"},"metadata":{}}]},{"cell_type":"code","source":"# x_train, y_train = create_dataset(examples[:10])\n# x_eval, y_eval = create_dataset(examples[10:20])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T10:43:47.499750Z","iopub.execute_input":"2021-07-05T10:43:47.500115Z","iopub.status.idle":"2021-07-05T10:43:47.826189Z","shell.execute_reply.started":"2021-07-05T10:43:47.500076Z","shell.execute_reply":"2021-07-05T10:43:47.824579Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-abfb74e63c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'examples' is not defined"],"ename":"NameError","evalue":"name 'examples' is not defined","output_type":"error"}]},{"cell_type":"code","source":"x_train, y_train = create_dataset(examples[:100000])\nx_eval, y_eval = create_dataset(examples[100000:])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:13:50.238042Z","iopub.execute_input":"2021-07-05T11:13:50.238394Z","iopub.status.idle":"2021-07-05T11:14:08.711351Z","shell.execute_reply.started":"2021-07-05T11:13:50.238359Z","shell.execute_reply":"2021-07-05T11:14:08.710310Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"input_word_ids (76924, 400)\ninput_type_ids (76924, 400)\ninput_mask (76924, 400)\nstart_token_idx (76924,)\nend_token_idx (76924,)\ninput_word_ids (6666, 400)\ninput_type_ids (6666, 400)\ninput_mask (6666, 400)\nstart_token_idx (6666,)\nend_token_idx (6666,)\n","output_type":"stream"}]},{"cell_type":"code","source":"start_logits = layers.Dense(1, name = 'start_logit', use_bias = False)(sequence_output)\nstart_logits = layers.Flatten()(start_logits)\n\nend_logits = layers.Dense(1, name = 'end_logit', use_bias = False)(sequence_output)\nend_logits = layers.Flatten()(end_logits)\n\nstart_prob = layers.Activation(keras.activations.softmax)(start_logits)\n\nend_prob = layers.Activation(keras.activations.softmax)(end_logits)\n\nmodel = keras.Model(inputs = [input_word_ids, input_mask, input_type_ids], outputs = [start_prob, end_prob])\nloss = keras.losses.SparseCategoricalCrossentropy(from_logits = False)\noptimizer = keras.optimizers.Adam(learning_rate = 1e-5, beta_1 = 0.9, beta_2=0.98, epsilon=1e-9)\nmodel.compile(optimizer=optimizer, loss=[loss, loss])\nmodel.summary()\nprint(\"length of dataset: \", len(x_train[0]))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:24:10.186970Z","iopub.execute_input":"2021-07-05T17:24:10.187433Z","iopub.status.idle":"2021-07-05T17:24:10.610803Z","shell.execute_reply.started":"2021-07-05T17:24:10.187399Z","shell.execute_reply":"2021-07-05T17:24:10.608169Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_word_ids (InputLayer)     [(None, 400)]        0                                            \n__________________________________________________________________________________________________\ninput_mask (InputLayer)         [(None, 400)]        0                                            \n__________________________________________________________________________________________________\ninput_type_ids (InputLayer)     [(None, 400)]        0                                            \n__________________________________________________________________________________________________\nkeras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n                                                                 input_mask[0][0]                 \n                                                                 input_type_ids[0][0]             \n__________________________________________________________________________________________________\nstart_logit (Dense)             (None, 400, 1)       768         keras_layer[0][1]                \n__________________________________________________________________________________________________\nend_logit (Dense)               (None, 400, 1)       768         keras_layer[0][1]                \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 400)          0           start_logit[0][0]                \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 400)          0           end_logit[0][0]                  \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 400)          0           flatten[0][0]                    \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 400)          0           flatten_1[0][0]                  \n==================================================================================================\nTotal params: 109,483,777\nTrainable params: 109,483,776\nNon-trainable params: 1\n__________________________________________________________________________________________________\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-22b07ba47b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"length of dataset: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"],"ename":"NameError","evalue":"name 'x_train' is not defined","output_type":"error"}]},{"cell_type":"code","source":"y_train_start[10]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:13:16.017123Z","iopub.execute_input":"2021-07-04T18:13:16.017477Z","iopub.status.idle":"2021-07-04T18:13:16.023172Z","shell.execute_reply.started":"2021-07-04T18:13:16.017447Z","shell.execute_reply":"2021-07-04T18:13:16.022252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.fit(generator(source_text,target_text,batch_size), epochs=5, steps_per_epoch = source_text.shape[0]/batch_size, validation_data = generator(source_text_val,target_text_val,batch_size), validation_steps = source_text_val.shape[0]/batch_size)\nbatch_size = 8\n# print(generator(x_train, y_train_start, y_train_end, batch_size))\n# x_eval, y_eval = generator(x_eval, y_eval, batch_size)\n# , validation_data = generator(data[:20], batch_size), validation_steps = 5\n# model.fit(generator(data, batch_size), epochs=2, steps_per_epoch = len(data['question'])/batch_size )\nmodel.fit([x_train[0], x_train[1], x_train[2]], [y_train[0], y_train[1]], epochs = 5, batch_size = batch_size, validation_data = ([x_eval[0], x_eval[1], x_eval[2]], [y_eval[0], y_eval[1]]))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:14:08.713131Z","iopub.execute_input":"2021-07-05T11:14:08.713474Z","iopub.status.idle":"2021-07-05T17:12:20.672362Z","shell.execute_reply.started":"2021-07-05T11:14:08.713437Z","shell.execute_reply":"2021-07-05T17:12:20.671513Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/5\n9616/9616 [==============================] - 4312s 447ms/step - loss: 8.3638 - activation_2_loss: 3.9550 - activation_3_loss: 4.4088 - val_loss: 6.8912 - val_activation_2_loss: 3.1922 - val_activation_3_loss: 3.6990\nEpoch 2/5\n9616/9616 [==============================] - 4295s 447ms/step - loss: 6.4633 - activation_2_loss: 2.9739 - activation_3_loss: 3.4894 - val_loss: 6.7127 - val_activation_2_loss: 3.1022 - val_activation_3_loss: 3.6105\nEpoch 3/5\n9616/9616 [==============================] - 4295s 447ms/step - loss: 5.6416 - activation_2_loss: 2.5557 - activation_3_loss: 3.0858 - val_loss: 6.7604 - val_activation_2_loss: 3.1463 - val_activation_3_loss: 3.6141\nEpoch 4/5\n9616/9616 [==============================] - 4295s 447ms/step - loss: 4.9337 - activation_2_loss: 2.1897 - activation_3_loss: 2.7440 - val_loss: 7.1081 - val_activation_2_loss: 3.3068 - val_activation_3_loss: 3.8014\nEpoch 5/5\n9616/9616 [==============================] - 4294s 447ms/step - loss: 4.2849 - activation_2_loss: 1.8621 - activation_3_loss: 2.4228 - val_loss: 7.7071 - val_activation_2_loss: 3.6322 - val_activation_3_loss: 4.0749\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f962ec6dc10>"},"metadata":{}}]},{"cell_type":"code","source":"model.save(\"../output/bert_model.h5\")\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:22:48.745110Z","iopub.execute_input":"2021-07-05T17:22:48.745544Z","iopub.status.idle":"2021-07-05T17:22:48.819756Z","shell.execute_reply.started":"2021-07-05T17:22:48.745459Z","shell.execute_reply":"2021-07-05T17:22:48.818436Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9a4a300c2057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../output/bert_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"model.load_weights(\"../output/bert_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:24:10.612042Z","iopub.status.idle":"2021-07-05T17:24:10.612516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /output/kaggle/working/bert","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:27:58.754293Z","iopub.execute_input":"2021-07-05T17:27:58.754712Z","iopub.status.idle":"2021-07-05T17:27:59.538532Z","shell.execute_reply.started":"2021-07-05T17:27:58.754674Z","shell.execute_reply":"2021-07-05T17:27:59.537012Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘/output/kaggle/working/bert’: No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd /kaggle/bert ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:27:04.584720Z","iopub.execute_input":"2021-07-05T17:27:04.585140Z","iopub.status.idle":"2021-07-05T17:27:05.334579Z","shell.execute_reply.started":"2021-07-05T17:27:04.585104Z","shell.execute_reply":"2021-07-05T17:27:05.333476Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/bert/bert.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:27:29.251089Z","iopub.execute_input":"2021-07-05T17:27:29.251794Z","iopub.status.idle":"2021-07-05T17:27:30.571854Z","shell.execute_reply.started":"2021-07-05T17:27:29.251740Z","shell.execute_reply":"2021-07-05T17:27:30.570749Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"ex = Sample(data['text'][30], data['question'][30])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:56:52.771641Z","iopub.execute_input":"2021-07-05T17:56:52.772005Z","iopub.status.idle":"2021-07-05T17:56:52.776753Z","shell.execute_reply.started":"2021-07-05T17:56:52.771975Z","shell.execute_reply":"2021-07-05T17:56:52.775978Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def test_preprocess(example):\n    dataset_dict = {\n        \"input_word_ids\": [],\n        \"input_type_ids\": [],\n        \"input_mask\": [],\n        \"start_token_idx\": [],\n        \"end_token_idx\": [],\n    }\n    if example.skip==False:\n      # print(ex.input_type_ids)\n      for key in dataset_dict:\n        dataset_dict[key].append(getattr(example, key))\n    for key in dataset_dict:\n        dataset_dict[key] = np.array(dataset_dict[key])\n    print(key, dataset_dict[key].shape)\n\n#   data_pd = pd.DataFrame.from_dict(dataset_dict)\n#   data_pd.to_pickle(\"/content/drive/MyDrive/NLP/final_dataset.pkl\")\n\n    train_x = np.array([dataset_dict[\"input_word_ids\"],\n         dataset_dict[\"input_mask\"],\n         dataset_dict[\"input_type_ids\"]])\n    train_y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n\n    return train_x, train_y\n\nex.pre_process()\nx_test, y_test = test_preprocess(ex)\nY = model.predict([x_test[0], x_test[1], x_test[2]])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:56:53.266897Z","iopub.execute_input":"2021-07-05T17:56:53.267448Z","iopub.status.idle":"2021-07-05T17:56:54.058939Z","shell.execute_reply.started":"2021-07-05T17:56:53.267413Z","shell.execute_reply":"2021-07-05T17:56:54.058106Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"end_token_idx (1,)\n","output_type":"stream"}]},{"cell_type":"code","source":"context = data['text'][30]\nprint(data['question'][30])\nprint(np.argmax(Y[0]), np.argmax(Y[1]))\nprint(data['start_id'][1], data['end_id'][1])\nprint(data['text'][30].split()[np.argmax(Y[0]) : np.argmax(Y[1])])\nprint(data['answer'][30])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:56:56.924525Z","iopub.execute_input":"2021-07-05T17:56:56.925199Z","iopub.status.idle":"2021-07-05T17:56:56.933405Z","shell.execute_reply.started":"2021-07-05T17:56:56.925158Z","shell.execute_reply":"2021-07-05T17:56:56.932624Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"What was she willing to give up\n153 371\n454 494\n['If', 'she', 'could', 'rule', 'this', 'gun-man,', 'as', 'Venters', 'had', 'called', 'him,', 'if', 'she', 'could', 'even', 'keep', 'him', 'from', 'shedding', 'blood,', 'what', 'strategy', 'to', 'play', 'his', 'flame', 'and', 'his', 'presence', 'against', 'the', 'game', 'of', 'oppression', 'her', 'churchmen', 'were', 'waging', 'against', 'her?', 'Never', 'would', 'she', 'forget', 'the', 'effect', 'on', 'Tull', 'and', 'his', 'men', 'when', 'Venters', 'shouted', \"Lassiter's\", 'name.', 'If', 'she', 'could', 'not', 'wholly', 'control', 'Lassiter,', 'then', 'what', 'she', 'could', 'do', 'might', 'put', 'off', 'the', 'fatal', 'day.', 'One', 'of', 'her', 'safe', 'racers', 'was', 'a', 'dark', 'bay,', 'and', 'she', 'called', 'him', 'Bells', 'because', 'of', 'the', 'way', 'he', 'struck', 'his', 'iron', 'shoes', 'on', 'the', 'stones.', 'When', 'Jerd', 'led', 'out', 'this', 'slender,', 'beautifully', 'built', 'horse', 'Lassiter', 'suddenly', 'became', 'all', 'eyes.', 'A', \"rider's\", 'love', 'of', 'a', 'thoroughbred', 'shone', 'in', 'them.', 'Round', 'and', 'round', 'Bells', 'he', 'walked,', 'plainly', 'weakening', 'all', 'the', 'time', 'in', 'his', 'determination', 'not', 'to', 'take', 'one', 'of', \"Jane's\", 'favorite', 'racers.']\nWhatever the price to be paid\n","output_type":"stream"}]},{"cell_type":"code","source":"print(Y[1].shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T17:57:36.208479Z","iopub.execute_input":"2021-07-05T17:57:36.208926Z","iopub.status.idle":"2021-07-05T17:57:36.214757Z","shell.execute_reply.started":"2021-07-05T17:57:36.208889Z","shell.execute_reply":"2021-07-05T17:57:36.213450Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"(1, 400)\n","output_type":"stream"}]},{"cell_type":"code","source":"import sklearn\nsklearn.save(\"bert_model\")\n\nfrom IPython.display import FileLink\nFileLink(‘bert_model.pth’)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T18:06:43.838760Z","iopub.execute_input":"2021-07-05T18:06:43.839175Z","iopub.status.idle":"2021-07-05T18:06:43.845644Z","shell.execute_reply.started":"2021-07-05T18:06:43.839141Z","shell.execute_reply":"2021-07-05T18:06:43.844367Z"},"trusted":true},"execution_count":50,"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-39d1a4bf68c1>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    FileLink(‘bert_model.pth’)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"],"ename":"SyntaxError","evalue":"invalid character in identifier (<ipython-input-50-39d1a4bf68c1>, line 5)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}